{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction  \n\n### Session purpose\nIn this session, we are introducing principle component analysis (PCA) and decision tree model. \nThis notebook has many sections empty with hints on how to complete them. We also provide a complete notebook which you can \nrefer to when you try to complete this exercise notebook.\n\n### Session contents\nIn this session, we will be covering the following topics:\n\n1. Data transformation - Principle Component Analysis;\n2. Multiclass classification;\n3. Decision tree classifier;\n4. Visualizing decision tree model;\n\n### About the data set  \nThe data set is actual satellite imagery of our home city of Asheville, taken from Landsat 8, an imaging satellite that was launched in 2013.\n\nCheck out the following links for more information: https://www.usgs.gov/land-resources/nli/landsat/landsat-8?qt-science_support_page_related_con=0#qt-science_support_page_related_con\n\nhttps://landsat.gsfc.nasa.gov/landsat-data-continuity-mission/ \n\nBefore we starts to read in the data and create our first classifier, we need to load libraries that will be used in the notebook. We will heavily rely on [**caret**](https://topepo.github.io/caret/index.html) library in R for model training. *caret* is a powerful wrapper package which calls hunders of machine learning packages in R and simplify model training and application process.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"library(caret); library(rpart)                                    # pacakge for ML model training\nlibrary(ggplot2); library(cowplot); library(rattle)               # package for visualization\nlibrary(readr); library(dplyr) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1 - Review of the data  \n\nIn this tutorial, we are still using the same dataset that we used during our previous training on land cover classification for Asheville area. Instead of going through each step in details, we will just do a quick review of the data.  \n\n### 1.1 - Data ingest \n\nFirst thing first, we will read in the data for this notebook which is included in this Github repository. The data file [*NC_L8_GroundTruth.csv*](https://github.com/geo-yrao/ML4ES-tutorials/blob/master/01-Data/NC_L8_GroundTruth.csv) contains sampled pixels in western North Carolina. The data contains both the multispectral reflectance from Landsat-8 OLI data and corresponding land cover types from USGS Cropland Data Layer (CDL). We can see the first 10 lines of the data. Our data contains the location (*\"Latitude\",\"Longitude\"*), land cover type (*\"Class\"*), and reflectance of six OLI channels (*\"B1\"~\"B6\"*). Let's first check how the data frame looks like."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Here, we read in the data pairs between reflectance (scale factor: 0.0001) and land cover types\nfname <- \"~/00-Data/NC_L8_GroundTruth.csv\"\nAVLData <- read_csv(fname); head(AVLData, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following table present the information about the six [OLI chanles](https://en.wikipedia.org/wiki/Landsat_8) included in the data. The reflectance data can provide unique information to charaterize different land cover types.\n\n| Channel No. | Channel Name | Wavelength |\n|-:|-:|:-:|\n|B1|Coastal/Areasol|0.433 – 0.453 μm| \n|B2|Blue|0.450 – 0.515 μm|\n|B3|Green|0.525 – 0.600 μm|\n|B4|Red|0.630 – 0.680 μm|\n|B5|Near Infrared|0.845 – 0.885 μm|\n|B6|Short Wavelength Infrared|1.560 – 1.660 μm|  \n\nIn our data, there are five different land cover types as listed in the table below.  \n\n| Class No. | Land Cover Type |\n|-:|-:|\n|0|Forest| \n|1|Corn|\n|2|Soy|\n|3|Development/Urban|\n|4|Water| \n\nIn this tutorials, we merge the two crop types (i.e., corn and soy) together to form a new class as \"Crop\" considering that they have quite similar spectral features which might lead to misclassification between them"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create a new variable for merged_class while preserve the original class label from data\n## Merge corn and soy into crop class (with code = 12) and conver it to a factor\nAVLData$merged_class <- factor(if_else((AVLData$Class == 1 | AVLData$Class == 2), 12, AVLData$Class),\n                               levels = c(0,12,3,4), labels = c(\"Forest\", \"Crop\", \"Urban\", \"Water\"))\n\n# Show the histogram of different land cover types using ggplot2\nAVLData %>% ggplot() + geom_bar(aes(merged_class), color=\"black\", fill=\"forestgreen\") +\n  labs(x=\"Land Cover Type\", y=\"No. of Samples\") + coord_cartesian(ylim=c(0,1150), expand=F) +\n  theme_bw() + theme(text=element_text(size=15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the data is overall well balanced across different land cover types except for forest (*Class == 0*). \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## We are now spliting the data set into training and testing data set\ntrainIndex <- createDataPartition(AVLData$merged_class, p=0.8, list=FALSE, times = 1)\n\n## 80% data is for training while 20% data is for independent testing\ntrainData <- AVLData[trainIndex,]; testData <- AVLData[-trainIndex,]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### 1.2 - Visualize the raw features  \n\nTypically, we need to examine the features in our dataset (i.e., the reflectance data from different channels) to make sure \nthat the features are appropriate.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"## In R base package, we can use the \"pairs\" function to visualize the pairwise scatter plot between each feature\n## This pairwise scatter plot will inform us if there are any correlations amongst different features.\nAVLData %>% select(B1:B6) %>% pairs(upper.panel=NULL, xlim=c(0,7000), ylim=c(0,7000), \n                                    pch=20, main=\"Pairwise Scatter Plots (Original)\", \n                                    col=rgb(65/255.,105/255.,225/255.,0.5))  ## We use rgb() function to increase the \n                                                                             ## transparency of the royalblue color","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This pairwise plot informs us that there are multiple channels that show strong linear relationship among them.  \nThis is a signal that we should either selecting a subset of the features or perform certain transformation of the features \nto produce a more representive feature space.  "},{"metadata":{},"cell_type":"markdown","source":"## 2 - Feature extraction/transformation  \n\nIn this notebook, we will mainly focus on [principle component analysis (PCA)](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c). PCA is a classic method for dimension reduction and feature transformation. It can help reduce the number of variables used in the analysis while retain the most of the information in a data set. It is most useful when you have a large data set and do not know which variable should be eliminated for your analysis.  \n\nPCA is included in the *caret* package as a method for data preprocessing. We can perform PCA analysis using *caret::preProcess()* function.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"## We only need the features of B1~B6 for the PCA transformation\ntrainData_X = trainData %>% select(B1:B6)\ntestData_X  = testData  %>% select(B1:B6)\n\n## Let's define the preprocessing piple line for our data using preProcess function first\n## to do PCA transformation, you only need to specify keyword \"method=...\" in the preProcess() function\n## Also, you can control how many pca components you want to preserve via key word \"pcaComp=...\"\n## It is always best to reserve the same amount of PCAs with the number of features that you \n## put into the PCA transformation, and you can decide how many you want to keep.\n## In our case, we want to keep all 6 PCAs and decide how many we will use later\npreProcess_steps = preProcess(...)\n\n## check the preProcess model information\npreProcess_steps\n\n## Once we define this pre-processing steps, we can perform the transformation\n## using the function predict()\npca_trainData_X = predict(...)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we want to look at what is the explained variances for each component after PCA.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"## calculate variances within each components\npca_vars <- (sapply(pca_trainData_X, sd))^2\ntotal_vars <- sum(pca_vars)\n\n## calculate the percentage of the variance explained by each components\n## we also want to reserve the component names (i.e., PC1, PC2, ...) so\n## we want to create a data frame\nexplained_var_perc <- data.frame(Components = ...,\n                                 Explained_var = ...)\n\n## Now we can plot out the explained variances of the PCA. \nexplained_var_perc %>% ...","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is apparent that the first two principle components can explain the majority of the variance in the features. Now, let's look at the \nnew pair wise scatter plot of the PCA data for the first three components which explains 99% of the overall data variance.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## In R base package, we can use the \"pairs\" function to visualize the pairwise scatter plot between each feature\n## This pairwise scatter plot will inform us if there are any correlations amongst different features.\n ## We use rgb() function to increase the transparency of the color\npca_trainData_X %>% select(PC1:PC3) %>% pairs(...) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exercise 1 - Examining separability of different classes\n\nCan you create a scatter plot between PC1 and PC2 to examine the seperability amongst the four target classes in our data (i.e., forest, crop,\nurban, and water)?"},{"metadata":{"trusted":true},"cell_type":"code","source":"### With the transformed data after PCA, we can create a data frame containing the PCA transformed \n### features and the merged classes.\npca_dataframe = data.frame(...)\n\n### With this data frame, we can create a scatter plot using merged_class to color our data points\n### using ggplot function.\n### The color list you can use is forest - \"darkforest\", crop - \"orange\", urban - \"grey50\", water - \"royalblue\"\n### To avoid point overlapping, you can set the alpha value equal to 0.5 or less.\n\n\n### What do you see from the color coded scatter plot?\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3 - Decision Tree  \n\nIn this section, we are going to implement a multiclass classifier using decision tree model. Decision tree model is the most intuitive \ntree-based machine learning model for both classification and regression problems. The most popular implementation of decision tree model is \nCART (Classification And Regression Tree). It recursively partitions the data via some decision rules based on the input features to predict \na categorical (classification) or continuous (regression) outcome. All the decision rules are learned from the training datasets and will be \napplied to testing data and future new data for the model. More information about decision tree in machine learning can be found on [this \nwebsite.](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/).  \n\nIn *caret* package, we are using the classic CART model for implement the multiclass classification applications. The tag for the CART model \nin *caret* is *\"rpart\"*. We can get more information about this model using *getModelInfo()* function in R.  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"getModelInfo(\"rpart\", regex=FALSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like we can tune the complexity parameters (i.e., *cp*) for *\"rpart\"* which controls the learning process and the final structure of \nour decision tree model.  \n\nFirst, let's define our training process via *trainControl()* function in *caret* package.  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Define training process using trainControl function and here we are NOT using cross validation to change the parameter cp\ndtCtrl <- trainControl(...)\n\nparams <- data.frame(cp=0.01) ## this is the default cp value 0.01\n\n## Here our target outcome is the merged class\ny_train <- trainData$merged_class; y_test <- testData$merged_class\n\n## Now we want to only use the first three components from PCA for our model training\nX_train <- pca_trainData_X[,1:3]\n\n## train the model using train function to train a decision tree model\n## using model tag \"rpart\"\ndtModel <- train(...)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Visualizing a decision tree  \n\nTo better understand how a decision tree will look like directly, we can use the *rattle* package to do so.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"## In rattle plot, we can use facyRpartPlot() function to do so on the finalModel from our dtModel.\nfancyRpartPlot(dtModel$finalModel, sub=\"Decision tree for multiclass classification\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nFrom the structure of this decision tree, we can see which features were used at different nodes and which leaf node corresponds to different \nclasses.  \n"},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Multiclass confusion matrix  \n\nIn this section, we will generate the confusion matrix for the decision tree multiclass classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Calculate confusion matrix for the training results.\ny_predicted_train <- predict(...)\ncfMatrix_train <- confusionMatrix(...)\ncfMatrix_train\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have an overall accuracy of 0.7874 for this four class classification with various performances for different classes. It appears that \ncrop and urban / forest have some mix-ups during the classification.  \n\nNow, we can apply this model to the independent testing data set and caculate for the confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"## We first need to apply the PCA transformation to our testing data\npca_testData_X <- predict(...)\n\n## with the PCA test data, we can apply the decision tree model to it\ny_predicted_test = predict(...)\n\n## With the calculated y label for testing data, we can now calculate the confusion matrix\ncfMatrix_test = confusionMatrix(...)\n\ncfMatrix_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bonus Exercise 2 - Using cross validation to explore the impact of *cp*\n\nAs we stated earlier, the complexity parameter (*cp*) of the model determines the structure/learning process of our decision tree.\nCan you implement a 5-fold cross validation to find the optimum *cp* value for the model? This time, we can use the random search \ncapability in *caret* with the function *train()* by specifying the key word *tuneLength=...*.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"### First, we need to define the training setting via the trainControl function.\n### We need to specify the method for cross validation as well as how we want to do the search.\n### This time, we are doing random search, which means we will set it as \"random\"\ncvControl = trainControl(...)\n\n### With the random search, we don't need to sepecify a parameter grid for the training process\n### to search through. We only need sepecify the numer of random parameters we want it to \n### search using the key word \"tuneLength=...\" in train() function\n### For us, let's say 10 times.\nset.seed(1031)\ndt_CV_random = train(...)\n\n### This shall give you the training results with 10 different *cp* values.\n### You can look at the results by simply print it out\ndt_CV_random\n\n### Can you see what are the cp values that the random search has went through?\n### What is the best cp value based on this random search?\n### Can you apply this final model to our testing data to look at the confusion matrix?\ny_predicted_random <- predict(...)\ncfMatrix_test_RandomSearch <- confusionMatrix(...)\ncfMatrix_test_RandomSearch","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}
