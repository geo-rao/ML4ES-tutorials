{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction  \n\n### Session purpose\nIn this session, we are introducing gaussian processes for regression applications (GPR). Before diving \ninto details about GPR, you should know that gaussian process can also be used for classification \napplications with the same procedure of GPR.\n\n### Learning outcome\nAfter going through this tutorial, you will be able to\n\n1. Handle a tabular dataset with missing values for regression applications;\n2. Implement gaussian process for regression applications;\n3. Understand the uncertainty of GPR estimation."},{"metadata":{},"cell_type":"markdown","source":"## 1 - Review the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"library(kernlab); library(caret)\nlibrary(dplyr); library(magrittr); \nlibrary(ggplot2); library(GGally)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are using the quality controlled daily station observations from US Climate Reference Network (USCRN). \nIn this notebook, we will use the data of Asheville station with nearly 10 years of data. First, let's read \nin the data from the CSV (comma separated variable) file from [our repository](https://github.com/geo-yrao/ML4ES-tutorials/tree/master/00-Data/USCRN-data)."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Define the file name of the CSV file\nfname <- \"https://raw.githubusercontent.com/geo-yrao/ML4ES-tutorials/master/00-Data/USCRN-data/USCRN-NC_Asheville_8_SSW_2010-2019.csv\"\n\n## Read in the RAW daily data\nRawData <- read.csv(fname)\n\n## Check the column names of the tabular data\nprint ( colnames(RawData) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the column names, we see that there are 28 different variables in this tabular data.\nWhat does each column means? It is all documented in the [readme file](https://github.com/geo-yrao/ML4ES-tutorials/blob/master/00-Data/USCRN-data/USCRN_Daily_Data_readme.txt).\n\n* _**WBANNO**_: The station WBAN number.\n* _**LST_DATE**_: The Local Standard Time (LST) date of the observation (YYYYMMDD).\n* _**CRX_VN**_: The version number of the station datalogger program.\n* _**LONGITUDE**_: Station longitude, using WGS-84 (unit: decimal_degrees_east).\n* _**LATITUDE**_: Station latitude, using WGS-84 (unit: decimal_degrees_north).\n* _**T_DAILY_MAX**_: Maximum air temperature (unit: Celsius).\n* _**T_DAILY_MIN**_: Minimum air temperature (unit: Celsius).\n* _**T_DAILY_MEAN**_: Mean air temperature calculated using maximum and minimum temperature (unit: Celsius).\n* _**T_DAILY_AVG**_: Average air temperature calculated using sub-hourly temperature (unit: Celsius).\n* _**P_DAILY_CALC**_: Total amount of precipitation (unit: mm).\n* _**SOLARAD_DAILY**_: Total solar energy (unit: MJ/m^2^).\n* _**SUR_TEMP_DAILY_TYPE**_: Type of infrared surface temperature measurement.\n* _**SUR_TEMP_DAILY_MAX**_: Maximum infrared surface temperature(unit: Celsius).\n* _**SUR_TEMP_DAILY_MIN**_: Minimum infrared surface temperature (unit: Celsius).\n* _**SUR_TEMP_DAILY_AVG**_: Average infrared surface temperature (unit: Celsius).\n* _**RH_DAILY_MAX**_: Maximum relative humidity (unit: %).\n* _**RH_DAILY_MIN**_: Minimum relative humidity (unit: %).\n* _**RH_DAILY_AVG**_: Average relative humidity (unit: %).\n* _**SOIL_MOISTURE_5_DAILY**_: Average soil moisture at 5 cm below the surface (unit: m^3^/m^3^).\n* _**SOIL_MOISTURE_10_DAILY**_: Average soil moisture at 10 cm below the surface (unit: m^3^/m^3^).\n* _**SOIL_MOISTURE_20_DAILY**_: Average soil moisture at 20 cm below the surface (unit: m^3^/m^3^).\n* _**SOIL_MOISTURE_50_DAILY**_: Average soil moisture at 50 cm below the surface (unit: m^3^/m^3^).\n* _**SOIL_MOISTURE_100_DAILY**_: Average soil moisture at 100 cm below the surface (unit: m^3^/m^3^).\n* _**SOIL_TEMP_5_DAILY**_: Average soil temperature at 5 cm below the surface (unit: Celsius).\n* _**SOIL_TEMP_10_DAILY**_: Average soil temperature at 10 cm below the surface (unit: Celsius).\n* _**SOIL_TEMP_20_DAILY**_: Average soil temperature at 20 cm below the surface (unit: Celsius).\n* _**SOIL_TEMP_50_DAILY**_: Average soil temperature at 50 cm below the surface (unit: Celsius).\n* _**SOIL_TEMP_100_DAILY**_: Average soil temperature at 100 cm below the surface (unit: Celsius).\n\nIn this notebook, we focus on the problem of estimating the average soil moisture at 10 cm below the \nsurface (_**SOIL_MOISTURE_10_DAILY**_) using other meteorological variables. To keep the model simple,\nwe just use the daily average (or total) of air temperature, precipitation, solar energy, surface \ntemperature, and relative humidity as the model input. Therefore, we need to simplify our current \ntabular data to only keep necessary variables.  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"### we only keep part of the variables for the application.\n## In addition to the input variables, we kept date to help us separate the data for training/testing\nSlimData <- RawData %>% select ( c(2, 9, 10, 11, 15, 18, 20) )\n\n## Change coloum names for simple display purpose\ncolnames(SlimData) <- c(\"Date\", \"T2m\", \"Precip\", \"Solar\", \"Tskin\", \"RH\", \"SM_10cm\")\n\n## Check the first & last 10 rows of the data\nhead(SlimData, 10) \ntail(SlimData, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nIn addition, we added one more variable called \"SM_10cm_lead\" which is the soil moisture data\nfrom the previous day."},{"metadata":{"trusted":true},"cell_type":"code","source":"SlimData$SM_10cm_lead <-  lag(SlimData$SM_10cm, n=1)\nstr(SlimData)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are missing values in both the independent variables and dependent variables in the \ncurrent data set. Let's see how many missing values exist in the current data set.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Summarize the missing value\nmissingSum <- SlimData %>% \n  select_if(function(x) any(is.na(x))) %>%           ## Check if the column contains missing value\n  summarise_all(funs(sum(is.na(.)/length(.)*100)))   ## if so, then count what percent of the data is missing\n\nprint(\"Percentage of missing values in each variable\")\nmissingSum %>% knitr::kable()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that there is ~20% of data records has missing value for the soil moisture. To proceed with \nmodel development, we will only keep the complete daily data records in this notebook. In the future, \nwe will introduce how to impute missing values for more complex model development.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"CleanData <- SlimData %>% filter(!is.na(T2m), !is.na(Precip),\n                                 !is.na(Solar), !is.na(Tskin),\n                                 !is.na(RH), !is.na(SM_10cm), !is.na(SM_10cm_lead))\n\nstr(CleanData)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we implement model development, we want to check the relationship between our variables.\nWe can examine the correlation between our variables pairwise except the date using function\n[_ggpairs()_](https://www.blopig.com/blog/2019/06/a-brief-introduction-to-ggpairs/)."},{"metadata":{"trusted":true},"cell_type":"code","source":"ggpairs(CleanData, columns = c(2:8),\n        lower = list(continuous = wrap(\"points\", alpha = 0.2, size=0.2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Right now, the *Date* variable is in the format of integer. We need to transform it into the \nspecific format for datetime in R so we can perform time based filtering for training/testing data \nspliting.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Convert data type for LST_DATE to Date in R following the format \"YYYY-MM-DD\"\nCleanData$Date <- as.Date(as.character(CleanData$Date), format=\"%Y%m%d\")\nstr(CleanData)\n\n## You will see the data type for LST_DATE has been changed into \"Date\"\n## with this data type, we can easily filter data by observation date for train/test data spliting\n\n## Let's use the data between 2010 and 2014 (5 years) for training our model\n## then, use the data after 2015 for model evaluation\ntrainData <- CleanData %>% filter(Date <= \"2014-12-31\"); dim(trainData)\ntestData  <- CleanData %>% filter(Date >= \"2015-01-01\"); dim(testData)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now have two different data sets for model development (*trainData*) and model evaluation (*testData*)\nseperately."},{"metadata":{},"cell_type":"markdown","source":"**Cautionary note**: when we split the data into two based on year, there is the underlying assumption \nthat we believe the *trainData* (2010-2014) comes from the same statistical distribution with the *testData*\n(2015-2019). In other words, the dataset used for model development could mostly represent the scenarios\nthat may appear in the dataset for model evaluation. But if there are future extreme events that is beyond the\nrange of *trainData*, we need to treat the prediction carefully since it could have large uncertainties. "},{"metadata":{},"cell_type":"markdown","source":"## 2 - Building a gaussian process regression model  \n\nWe are now moving on to develop the GPR model to estimate daily soil moisture at 10 cm using daily\nmeteorological variables from USCRN station in Asheville.\n\nIn R, the GPR can be implemented using the library **kernlab**. We will use the combination of **caret**\nand **kernlab** in this tutorial to implement GPR for our USCRN data.  \n\nThe GPR model relies on the kernal function to estimate the covariance matrix. In this tutorial, we will\nuse the radial basis function (RBF) as an example. In **caret** packege, the RBF-kernal GPR model is using \nthe model tag of *\"gaussRadial\"*. To examine the model information from **caret**, we can use *getModelInfo()*."},{"metadata":{"trusted":true},"cell_type":"code","source":"getModelInfo(model = \"gaussprRadial\", regex = FALSE)[[1]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the model information, this RBF kernal based GPR model has only one hyperparameter *\"sigma\"* \nto be tuned which determins the smoothness of the covirance. \n\nFirst of all, we need to scale all data to avoid that some large magnitute variables may dominate \nthe model performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"## we will use preProcess function to do the scaling\n## Also, we are not scaling the date for the data\npreProc <- preProcess(trainData[,2:8], method = c(\"center\", \"scale\"))\n\n## Now, we apply the preprocessing steps to both training data and testing data\ntrainScaled <- predict(preProc, newdata=trainData)\ntestScaled  <- predict(preProc, newdata=testData)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the scaled data, now we can define the grid search space for our hyperparameter search. Also, we\nwill keep using the 5-fold cross validation for our hyperparameter search."},{"metadata":{"trusted":true},"cell_type":"code","source":"## First, define model training control & grid for our hyperparameter training\nparaGrid <- expand.grid(\n    sigma = c(0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1.28)\n)\n\n### To specify that we want to do 5-fold CV, we need to use the function trainControl() from *caret*.\ntrCtrl <- trainControl(method=\"cv\", number=5, search=\"grid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now, we are training our R model using a 5-fold cross validation by searching through eight different \nsigma values.\n\nWith the defined hyperparameter grid and training configuration (5-fold cross validation), we can now \nmove forward to train our GPR model. \n\nFrom our last SVR tutorial, we have concluded the temporal autocorrelation may help improve our model\nperformance. This is supported by our pairwise scatter plot as well. So our model will include the \nsoil moisture data from previous data as an input to account for the \"memory\" in the soil."},{"metadata":{"trusted":true},"cell_type":"code","source":"### Using train function to train the linear SVR model\n## target : Soil Moisture at 10 cm SM_10cm\n## input  : T2m, Precip, Solar, Tskin, RH, SM_10cm from previous day\nrbfGPR <- train(SM_10cm ~ T2m + Precip + Solar + Tskin + RH + SM_10cm_lead,\n                data = trainScaled, method = \"gaussprRadial\", \n                tuneGrid = paraGrid,\n                trControl = trCtrl,\n                variance.model = TRUE)\n\n### Now we have our RBF GPR model with the optimized hyperparameter\nrbfGPR","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this gaussian process regression by accounting for the \"memory\" from previous day, \nour model achieves the coefficient of determination (R^{2}) of 0.95. Let's see how this model will \nperform on the testing data that we set asside. "},{"metadata":{"trusted":true},"cell_type":"code","source":"### First, we apply the model to the test data by using function predict()\nrbfPredicted <- predict(rbfGPR, newdata = testScaled)\n\n### Now, we want to calculate the RMSE, R^2, and mean absolute error (MAE) using \n### postResample() function\nrbfTesting <- postResample(rbfPredicted, testScaled$SM_10cm)\n\nrbfTesting","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The GPR model estimation shows a very good performance with R^{2} reaching 0.96 and RMSE of 0.25 for \nthe scaled soil moisture value.  \n\nNow, we can visualize our model performance by ploting the true value and the estimation against the \ndate.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Define the result data frame first for ggplot\nresult <- data.frame(Date = testScaled$Date, \n                     Scaled_USCRN_SM_10cm = testScaled$SM_10cm,\n                     Scaled_GPR_SM_10cm = rbfPredicted)\n\n## Note that all values are scaled values in the preProcessing step\nggplot(aes(x=Date), data=result) +\n    geom_point(aes(y=Scaled_USCRN_SM_10cm), color = \"royalblue\", pch=21) +\n    geom_point(aes(y=Scaled_GPR_SM_10cm), color = \"black\", pch=21) +\n    theme_bw() + labs(x = \"Date\", y = \"Scaled Soil Moisture at 10 cm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot, we see that the estimated soil mositure data at 10 cm follows similar temporal\npattern with the observed values.\n\nOne of the great advantage of GPR is that it can generate uncertainty measure. So how can we\nvisualize the uncertainty of our estimation? Fortunately, **kernlab** allow you to produce \nthe uncertainty of the estimated value using *predict()* function by specifying the keyword \n*type = \"sdeviation\"*.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"### First we extracting the final GPR model from our 5-fold CV\ngprModel <- rbfGPR$finalModel\n\n### Now, we will use the kernlab::predict function to get the uncertainty output\nrbfUncertainty <- kernlab::predict(gprModel, testScaled[,c(2:6,8)], type=\"sdeviation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This uncertainty measure is assoiciated with each test data points we have. We can't\nvisualize it like the theoretical GPR analysis since our model is a multivariate model.\nBut we can present the uncertainty for associated estimation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Assign the uncertainty vector into our result data frame\nresult$uncertainty = rbfUncertainty\n\n## Visualize the uncertainty using an error bar\n## Note that all values are scaled values in the preProcessing step\nggplot(aes(x=Date), data=result) +\n    geom_point(aes(y=Scaled_GPR_SM_10cm), color = \"black\", pch=21) +\n    geom_errorbar(aes(ymin=Scaled_GPR_SM_10cm-uncertainty, \n                      ymax=Scaled_GPR_SM_10cm+uncertainty)) +\n    theme_bw() + labs(x = \"Date\", y = \"Scaled Soil Moisture at 10 cm\")\n\n## To better examine the uncertainty we further zoom into one year (2015) \n## using the limit function in ggplot\nggplot(aes(x=Date), data=result) +\n    geom_point(aes(y=Scaled_GPR_SM_10cm), color = \"black\", pch=21) +\n    geom_errorbar(aes(ymin=Scaled_GPR_SM_10cm-uncertainty, \n                      ymax=Scaled_GPR_SM_10cm+uncertainty)) +\n    theme_bw() + labs(x = \"Date\", y = \"Scaled Soil Moisture at 10 cm\") +\n    scale_x_date(limits=c(as.Date(\"2015-01-01\"), as.Date(\"2015-12-31\")))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the associated uncertainty can be a good indicator for further application \nof this model output because it informs the user how confident we are about the model output.\nThis is the most powerful part of the GPR model.  \n\nNow, you might say we are \"cheating\" to use the soil moisture data from previous day as the\nfirst guess for this model. So it is really easy to get the model right. Can you build a model\nthat do not rely on the soil moisture data from previous days?\n\n## Exercise 1\nNow, it's your turn to do some exercise! Can you try to build a model adding day of year as \na model input but do not use the soil moisture from previous data to build a GPR model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### We have all the data ready and the formula ready\n#### The only thing you need to think about and adjust is the changing the model input\n#### as well as what hyperparameters that you want to tune.\n\n#### Can you implement your GPR model here?\n\n\n#### How about this model compared to the previous model we developed?\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exercise 2\nCan you change the kernal for the GPR model? How about let's try a model with a linear\nkearnal?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### We have all the data ready and the formula ready\n#### The only thing you need to think about and adjust is the changing the model tag\n#### to represent a linear kernal GPR model\n\n#### Can you implement your GPR model here?\n\n\n#### How about this model compared to the previous model we developed?\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}